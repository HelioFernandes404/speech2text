import whisper
import torch


def transcribe_audio(audio_path: str, modelo: str = "large-v3", device: str = "cpu") -> str:
    """Transcreve √°udio para texto usando Whisper com m√°xima precis√£o"""
    try:
        if device == "cuda" and not torch.cuda.is_available():
            print("‚ö†Ô∏è CUDA n√£o dispon√≠vel. Usando CPU.")
            device = "cpu"

        print(f"üöÄ Carregando modelo {modelo} ({device.upper()})...")
        model = whisper.load_model(modelo, device=device)

        print("\nüîä Iniciando transcri√ß√£o...")
        resultado = model.transcribe(
            audio_path,
            language="pt",
            verbose=True,
            temperature=0.0,
            beam_size=5,
            best_of=5,
            compression_ratio_threshold=2.4,
            no_speech_threshold=0.6,
            initial_prompt="Transcri√ß√£o de alta precis√£o com Whisper large-v3."
        )
        
        return str(resultado["text"])
    except Exception as e:
        raise RuntimeError(f"Erro na transcri√ß√£o: {str(e)}")